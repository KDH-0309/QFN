#!/usr/bin/env python3
"""
Portfolio Optimization using Modern Portfolio Theory and Quantum Algorithms
Optimizes stock portfolio allocation based on risk and return
"""

import json
import sys
import numpy as np
from datetime import datetime
import time

# Quantum computing imports
try:
    from qiskit import QuantumCircuit
    from qiskit.primitives import StatevectorSampler as Sampler
    from qiskit_algorithms import QAOA, VQE
    from qiskit_algorithms.optimizers import COBYLA, SLSQP
    from qiskit_optimization import QuadraticProgram
    from qiskit_optimization.algorithms import MinimumEigenOptimizer
    from qiskit_optimization.converters import QuadraticProgramToQubo
    from qiskit.circuit.library import TwoLocal
    QUANTUM_AVAILABLE = True
    print("âœ… Quantum computing libraries loaded successfully", file=sys.stderr)
except ImportError as e:
    QUANTUM_AVAILABLE = False
    print(f"Warning: Qiskit not available. Quantum algorithms disabled. Error: {e}", file=sys.stderr)


def load_input_data(input_file):
    """Load optimization request data from JSON file"""
    with open(input_file, 'r', encoding='utf-8-sig') as f:
        return json.load(f)


def fetch_real_historical_data(stocks, period='1y', use_real_data=True):
    """
    Fetch REAL historical stock data using yfinance
    Calculate actual returns and covariance from market data
    """
    if not use_real_data:
        return fetch_simulated_data(stocks)
    
    try:
        import yfinance as yf
        import pandas as pd
        
        print(f"Fetching real data for {len(stocks)} stocks, period: {period}...", file=sys.stderr)
        
        # Get stock symbols
        symbols = [stock['symbol'] for stock in stocks]
        
        # Download historical data
        data = yf.download(symbols, period=period, progress=False)
        
        if data.empty:
            print("Warning: No data fetched, falling back to simulation", file=sys.stderr)
            return fetch_simulated_data(stocks)
        
        # Calculate daily returns
        if len(symbols) == 1:
            prices = data['Close']
            returns_data = prices.pct_change().dropna()
            mean_returns = np.array([returns_data.mean() * 252])  # Annualized
            cov_matrix = np.array([[returns_data.std() ** 2 * 252]])  # Annualized
        else:
            prices = data['Close']
            returns_data = prices.pct_change().dropna()
            
            # Annualized returns (252 trading days)
            mean_returns = returns_data.mean() * 252
            
            # Annualized covariance matrix
            cov_matrix = returns_data.cov() * 252
            
            # Convert to numpy arrays
            mean_returns = mean_returns.values
            cov_matrix = cov_matrix.values
        
        print(f"âœ… Real data fetched successfully", file=sys.stderr)
        print(f"Mean returns: {mean_returns}", file=sys.stderr)
        
        return mean_returns, cov_matrix
        
    except Exception as e:
        print(f"Error fetching real data: {e}", file=sys.stderr)
        print("Falling back to simulated data", file=sys.stderr)
        return fetch_simulated_data(stocks)


def fetch_simulated_data(stocks):
    """
    Simulated data based on risk levels (original implementation)
    Used as fallback when real data unavailable
    """
    n_stocks = len(stocks)
    
    # Fix random seed for consistent results based on stock symbols
    seed = sum([ord(c) for stock in stocks for c in stock['symbol']]) % 10000
    np.random.seed(seed)
    
    # Simulate returns based on risk levels
    returns = []
    for stock in stocks:
        risk = stock['riskLevel']
        expected_return = 0.05 + (risk / 100.0) * 0.15
        returns.append(expected_return)
    
    returns = np.array(returns)
    
    # Generate covariance matrix based on risk levels
    volatility = np.array([stock['riskLevel'] / 100.0 * 0.3 for stock in stocks])
    correlation_matrix = np.random.uniform(0.3, 0.7, (n_stocks, n_stocks))
    np.fill_diagonal(correlation_matrix, 1.0)
    correlation_matrix = (correlation_matrix + correlation_matrix.T) / 2
    
    covariance_matrix = np.outer(volatility, volatility) * correlation_matrix
    
    return returns, covariance_matrix


def fetch_historical_data(stocks, use_real_data=True):
    """
    Main function to fetch historical data
    Supports both real and simulated data
    """
    return fetch_real_historical_data(stocks, period='1y', use_real_data=use_real_data)


def build_portfolio_optimization_problem(returns, covariance_matrix, risk_factor):
    """
    Build portfolio optimization using Mean-Variance Optimization
    """
    if returns is None or len(returns) == 0:
        raise ValueError("Returns data is empty or None")
    if covariance_matrix is None:
        raise ValueError("Covariance matrix is None")
    n = len(returns)
    return n, returns, covariance_matrix, risk_factor


def optimize_with_modern_portfolio_theory(n, returns, covariance_matrix, risk_factor, constraints=None):
    """
    Run Modern Portfolio Theory optimization
    Uses analytical solution for optimal portfolio weights with optional constraints
    
    constraints: dict with 'min_weights' and 'max_weights' arrays
    """
    try:
        from scipy.optimize import minimize
        
        # If no constraints, use simple analytical solution
        if constraints is None:
            # Calculate inverse covariance matrix
            inv_cov = np.linalg.inv(covariance_matrix)
            
            # Optimal weights with risk aversion parameter
            ones = np.ones(n)
            
            # Mean-variance optimization formula
            # w = (1/lambda) * Sigma^-1 * mu
            # where lambda is risk aversion coefficient
            risk_aversion = 2.0 / risk_factor if risk_factor > 0 else 1.0
            
            # Calculate optimal weights
            weights = np.dot(inv_cov, returns) / risk_aversion
            
            # Normalize to sum to 1
            if weights.sum() > 0:
                weights = weights / weights.sum()
            else:
                weights = np.ones(n) / n
            
            # Ensure all weights are non-negative (long-only portfolio)
            weights = np.maximum(weights, 0)
            weights = weights / weights.sum()
            
            return weights
        
        # With constraints, use scipy optimizer
        min_weights = constraints.get('min_weights', np.zeros(n))
        max_weights = constraints.get('max_weights', np.ones(n))
        
        # Objective function: maximize Sharpe ratio (minimize negative Sharpe)
        def objective(w):
            portfolio_return = np.dot(w, returns)
            portfolio_variance = np.dot(w, np.dot(covariance_matrix, w))
            portfolio_risk = np.sqrt(portfolio_variance)
            
            risk_free_rate = 0.02
            sharpe = (portfolio_return - risk_free_rate) / portfolio_risk if portfolio_risk > 0 else 0
            
            return -sharpe  # Minimize negative Sharpe = Maximize Sharpe
        
        # Constraints
        constraints_list = [
            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}  # Weights sum to 1
        ]
        
        # Bounds for each weight
        bounds = [(min_weights[i], max_weights[i]) for i in range(n)]
        
        # Initial guess (equal weights within bounds)
        initial_weights = np.array([
            (min_weights[i] + max_weights[i]) / 2 for i in range(n)
        ])
        initial_weights = initial_weights / initial_weights.sum()
        
        # Optimize
        result = minimize(
            objective,
            initial_weights,
            method='SLSQP',
            bounds=bounds,
            constraints=constraints_list,
            options={'maxiter': 1000}
        )
        
        if result.success:
            weights = result.x
            # Ensure weights sum to 1 and are within bounds
            weights = np.clip(weights, min_weights, max_weights)
            weights = weights / weights.sum()
            return weights
        else:
            print(f"Optimization with constraints failed: {result.message}", file=sys.stderr)
            # Return feasible weights within constraints
            weights = initial_weights
            return weights
        
    except Exception as e:
        print(f"Portfolio optimization failed: {e}", file=sys.stderr)
        # Fallback to equal weights
        return np.ones(n) / n


def calculate_allocations(stocks, weights):
    """
    Calculate portfolio allocations based on optimization weights
    """
    # Calculate allocations
    allocations = {}
    for i, stock in enumerate(stocks):
        symbol = stock['symbol']
        allocation_pct = float(weights[i] * 100)
        allocations[symbol] = round(allocation_pct, 2)
    
    return allocations


def calculate_portfolio_metrics(returns, covariance_matrix, weights):
    """Calculate portfolio performance metrics"""
    # Expected return
    portfolio_return = float(np.dot(weights, returns))
    
    # Portfolio risk (standard deviation)
    portfolio_variance = np.dot(weights, np.dot(covariance_matrix, weights))
    portfolio_risk = float(np.sqrt(portfolio_variance))
    
    # Sharpe ratio (assuming risk-free rate = 0.02)
    risk_free_rate = 0.02
    sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_risk if portfolio_risk > 0 else 0
    
    return {
        'expectedReturn': round(portfolio_return * 100, 2),
        'expectedRisk': round(portfolio_risk * 100, 2),
        'sharpeRatio': round(sharpe_ratio, 3)
    }


def generate_efficient_frontier(returns, covariance_matrix, num_portfolios=100):
    """
    Generate efficient frontier data
    Returns list of portfolios on the efficient frontier
    """
    n_assets = len(returns)
    results = []
    
    # Generate random portfolios
    np.random.seed(42)  # For reproducibility
    
    for _ in range(num_portfolios):
        # Random weights
        weights = np.random.random(n_assets)
        weights = weights / np.sum(weights)
        
        # Calculate metrics
        portfolio_return = np.dot(weights, returns)
        portfolio_variance = np.dot(weights, np.dot(covariance_matrix, weights))
        portfolio_risk = np.sqrt(portfolio_variance)
        
        risk_free_rate = 0.02
        sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_risk if portfolio_risk > 0 else 0
        
        results.append({
            'risk': round(portfolio_risk * 100, 2),
            'return': round(portfolio_return * 100, 2),
            'sharpe': round(sharpe_ratio, 3)
        })
    
    # Sort by risk
    results.sort(key=lambda x: x['risk'])
    
    # Filter to get efficient frontier (remove dominated portfolios)
    efficient_frontier = []
    max_return = -float('inf')
    
    for portfolio in results:
        if portfolio['return'] > max_return:
            max_return = portfolio['return']
            efficient_frontier.append(portfolio)
    
    return efficient_frontier


def backtest_optimization(stocks, periods=['3mo', '6mo', '1y']):
    """
    Backtest optimization: simulate past optimization and compare with actual results
    
    For each period:
    1. Fetch data up to [period] ago
    2. Run optimization with that historical data
    3. Fetch actual returns from then to now
    4. Compare predicted vs actual performance
    """
    try:
        import yfinance as yf
        import pandas as pd
        from dateutil.relativedelta import relativedelta
        
        symbols = [stock['symbol'] for stock in stocks]
        backtest_results = []
        
        print(f"Starting backtest for {len(symbols)} stocks...", file=sys.stderr)
        
        for period in periods:
            try:
                # Parse period (e.g., '3mo' -> 3 months)
                if period.endswith('mo'):
                    months = int(period[:-2])
                    lookback_date = datetime.now() - relativedelta(months=months)
                elif period.endswith('y'):
                    years = int(period[:-1])
                    lookback_date = datetime.now() - relativedelta(years=years)
                else:
                    continue
                
                # 1. Fetch historical data UP TO lookback_date (for optimization)
                training_start = lookback_date - relativedelta(years=1)
                data_training = yf.download(
                    symbols, 
                    start=training_start.strftime('%Y-%m-%d'),
                    end=lookback_date.strftime('%Y-%m-%d'),
                    progress=False
                )
                
                if data_training.empty:
                    print(f"Warning: No training data for period {period}", file=sys.stderr)
                    continue
                
                # Calculate returns and covariance from training data
                if len(symbols) == 1:
                    prices_train = data_training['Close']
                    returns_train = prices_train.pct_change().dropna()
                    mean_returns_train = np.array([returns_train.mean() * 252])
                    cov_matrix_train = np.array([[returns_train.std() ** 2 * 252]])
                else:
                    prices_train = data_training['Close']
                    returns_train = prices_train.pct_change().dropna()
                    mean_returns_train = returns_train.mean().values * 252
                    cov_matrix_train = returns_train.cov().values * 252
                
                # 2. Optimize portfolio based on training data
                n_stocks = len(symbols)
                risk_factor = 5.0  # Default risk level
                optimal_weights = optimize_with_modern_portfolio_theory(
                    n_stocks, mean_returns_train, cov_matrix_train, risk_factor
                )
                predicted_metrics = calculate_portfolio_metrics(
                    mean_returns_train, cov_matrix_train, optimal_weights
                )
                
                # 3. Fetch actual data FROM lookback_date TO now
                data_actual = yf.download(
                    symbols,
                    start=lookback_date.strftime('%Y-%m-%d'),
                    end=datetime.now().strftime('%Y-%m-%d'),
                    progress=False
                )
                
                if data_actual.empty:
                    print(f"Warning: No actual data for period {period}", file=sys.stderr)
                    continue
                
                # Calculate actual returns
                if len(symbols) == 1:
                    prices_actual = data_actual['Close']
                    returns_actual = prices_actual.pct_change().dropna()
                    mean_returns_actual = np.array([returns_actual.mean() * 252])
                    cov_matrix_actual = np.array([[returns_actual.std() ** 2 * 252]])
                else:
                    prices_actual = data_actual['Close']
                    returns_actual = prices_actual.pct_change().dropna()
                    mean_returns_actual = returns_actual.mean().values * 252
                    cov_matrix_actual = returns_actual.cov().values * 252
                
                # 4. Calculate actual metrics with optimized weights
                actual_metrics = calculate_portfolio_metrics(
                    mean_returns_actual, cov_matrix_actual, optimal_weights
                )
                
                # Also calculate equal-weight baseline
                equal_weights = np.ones(len(symbols)) / len(symbols)
                baseline_metrics = calculate_portfolio_metrics(
                    mean_returns_actual, cov_matrix_actual, equal_weights
                )
                
                backtest_results.append({
                    'period': period,
                    'lookbackDate': lookback_date.strftime('%Y-%m-%d'),
                    'predicted': {
                        'return': round(predicted_metrics['expectedReturn'], 2),
                        'risk': round(predicted_metrics['expectedRisk'], 2),
                        'sharpe': round(predicted_metrics['sharpeRatio'], 3)
                    },
                    'actual': {
                        'return': round(actual_metrics['expectedReturn'], 2),
                        'risk': round(actual_metrics['expectedRisk'], 2),
                        'sharpe': round(actual_metrics['sharpeRatio'], 3)
                    },
                    'baseline': {
                        'return': round(baseline_metrics['expectedReturn'], 2),
                        'risk': round(baseline_metrics['expectedRisk'], 2),
                        'sharpe': round(baseline_metrics['sharpeRatio'], 3)
                    },
                    'outperformance': round(actual_metrics['expectedReturn'] - baseline_metrics['expectedReturn'], 2)
                })
                
                print(f"âœ… Backtest for {period}: Predicted {predicted_metrics['expectedReturn']:.1f}%, Actual {actual_metrics['expectedReturn']:.1f}%", file=sys.stderr)
                
            except Exception as e:
                print(f"Error in backtest for period {period}: {e}", file=sys.stderr)
                continue
        
        return backtest_results
        
    except ImportError:
        print("Warning: yfinance or dateutil not available for backtesting", file=sys.stderr)
        return []
    except Exception as e:
        print(f"Error in backtesting: {e}", file=sys.stderr)
        return []


def generate_optimization_reason(stocks, weights, returns, covariance_matrix, metrics, target_risk):
    """Generate detailed optimization strategy explanation with reasoning"""
    n_stocks = len(stocks)
    portfolio_return = metrics['expectedReturn']
    portfolio_risk = metrics['expectedRisk']
    sharpe_ratio = metrics['sharpeRatio']
    
    # Calculate correlations between stocks
    if n_stocks > 1:
        # Calculate correlation from covariance matrix
        std_devs = np.sqrt(np.diag(covariance_matrix))
        correlation_matrix = covariance_matrix / np.outer(std_devs, std_devs)
        # Get average correlation (excluding diagonal)
        avg_correlation = np.mean(np.abs(correlation_matrix[np.triu_indices_from(correlation_matrix, k=1)]))
    else:
        correlation_matrix = np.array([[1.0]])
        avg_correlation = 0.0
    
    # Find top allocated stocks with details
    stock_details = []
    for i in range(n_stocks):
        stock_details.append({
            'name': stocks[i]['name'],
            'symbol': stocks[i]['symbol'],
            'weight': weights[i] * 100,
            'return': returns[i] * 100,
            'risk': stocks[i]['riskLevel'],
            'variance': covariance_matrix[i, i] * 100
        })
    stock_details.sort(key=lambda x: x['weight'], reverse=True)
    
    # Generate comprehensive reason
    reason = f"## ğŸ¯ ìµœì í™” ë¶„ì„ ê²°ê³¼\n\n"
    reason += f"ìœ„í—˜ ìˆ˜ì¤€ {target_risk}/10ì— ë§ì¶° **ìœ„í—˜ ëŒ€ë¹„ ìµœëŒ€ ìˆ˜ìµ**ì„ ì¶”êµ¬í•˜ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.\n\n"
    
    # Portfolio characteristics
    reason += f"### ğŸ“Š ìµœì í™”ëœ í¬íŠ¸í´ë¦¬ì˜¤ íŠ¹ì„±\n\n"
    reason += f"| ì§€í‘œ | ê°’ | í‰ê°€ |\n"
    reason += f"|------|------|------|\n"
    reason += f"| **ì˜ˆìƒ ì—°ê°„ ìˆ˜ìµë¥ ** | {portfolio_return:.2f}% | "
    if portfolio_return > 20:
        reason += "ë§¤ìš° ë†’ìŒ ğŸš€ |\n"
    elif portfolio_return > 10:
        reason += "ë†’ìŒ ğŸ“ˆ |\n"
    elif portfolio_return > 5:
        reason += "ì ì • âœ… |\n"
    else:
        reason += "ë³´ìˆ˜ì  ğŸ›¡ï¸ |\n"
    
    reason += f"| **í¬íŠ¸í´ë¦¬ì˜¤ ë³€ë™ì„±** | {portfolio_risk:.2f}% | "
    if portfolio_risk < 15:
        reason += "ë‚®ìŒ (ì•ˆì •ì ) |\n"
    elif portfolio_risk < 25:
        reason += "ì ì • |\n"
    else:
        reason += "ë†’ìŒ (ì£¼ì˜) |\n"
    
    reason += f"| **ìƒ¤í”„ ì§€ìˆ˜** | {sharpe_ratio:.3f} | "
    if sharpe_ratio > 2.0:
        reason += "ë§¤ìš° ìš°ìˆ˜ â­â­â­ |\n"
    elif sharpe_ratio > 1.0:
        reason += "ìš°ìˆ˜ â­â­ |\n"
    elif sharpe_ratio > 0.5:
        reason += "ì–‘í˜¸ â­ |\n"
    else:
        reason += "ê°œì„  í•„ìš” |\n"
    
    reason += f"| **ì¢…ëª© ê°„ í‰ê·  ìƒê´€ê³„ìˆ˜** | {avg_correlation:.3f} | "
    if avg_correlation < 0.3:
        reason += "ë¶„ì‚° íš¨ê³¼ ë†’ìŒ âœ… |\n"
    elif avg_correlation < 0.6:
        reason += "ì ì •í•œ ë¶„ì‚° |\n"
    else:
        reason += "ë¶„ì‚° íš¨ê³¼ ë‚®ìŒ âš ï¸ |\n"
    
    reason += f"\n"
    
    # 3. Why these weights?
    reason += f"### ğŸ¯ ì¢…ëª©ë³„ ë°°ë¶„ ê·¼ê±°\n\n"
    for idx, stock in enumerate(stock_details[:5], 1):  # Top 5 stocks
        reason += f"**{idx}. {stock['name']} ({stock['symbol']})** - {stock['weight']:.1f}%\n"
        reason += f"```\n"
        reason += f"â€¢ ì˜ˆìƒ ìˆ˜ìµë¥ : {stock['return']:.2f}% (ì—°ê°„)\n"
        reason += f"â€¢ ìœ„í—˜ë„: {stock['risk']}/10\n"
        reason += f"â€¢ ë³€ë™ì„±: {np.sqrt(stock['variance']):.2f}%\n"
        
        # Reasoning for this weight
        if stock['weight'] > 30:
            reason += f"â€¢ ë¹„ì¤‘ ì´ìœ : ë†’ì€ ìˆ˜ìµë¥ ({stock['return']:.1f}%)ê³¼ ì ì ˆí•œ ë¦¬ìŠ¤í¬ë¡œ í•µì‹¬ ë³´ìœ  ì¢…ëª©\n"
        elif stock['weight'] > 20:
            reason += f"â€¢ ë¹„ì¤‘ ì´ìœ : ìš°ìˆ˜í•œ ìˆ˜ìµë¥ ê³¼ í¬íŠ¸í´ë¦¬ì˜¤ ì•ˆì •ì„± ê¸°ì—¬\n"
        elif stock['weight'] > 10:
            reason += f"â€¢ ë¹„ì¤‘ ì´ìœ : ë¶„ì‚°íˆ¬ì íš¨ê³¼ë¡œ ì „ì²´ ë¦¬ìŠ¤í¬ ê°ì†Œ\n"
        else:
            reason += f"â€¢ ë¹„ì¤‘ ì´ìœ : ì†ŒëŸ‰ ë³´ìœ ë¡œ ì¶”ê°€ ë¶„ì‚° íš¨ê³¼ ì œê³µ\n"
        
        reason += f"```\n\n"
    
    # 4. Strategy explanation
    reason += f"### ğŸ’­ ìµœì í™” ì „ëµ ì„¤ëª…\n\n"
    
    if sharpe_ratio > 1.5:
        reason += f"**âœ… ìœ„í—˜ ëŒ€ë¹„ ìˆ˜ìµì´ ë§¤ìš° ìš°ìˆ˜í•œ í¬íŠ¸í´ë¦¬ì˜¤**\n\n"
        reason += f"ìƒ¤í”„ ì§€ìˆ˜ {sharpe_ratio:.3f}ëŠ” íˆ¬ìí•œ ìœ„í—˜ 1ë‹¨ìœ„ë‹¹ {sharpe_ratio:.2f}ë°°ì˜ ì´ˆê³¼ìˆ˜ìµì„ ì–»ì„ ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. "
        reason += f"ì´ëŠ” ì‹œì¥ í‰ê· (ìƒ¤í”„ ì§€ìˆ˜ 1.0)ì„ í¬ê²Œ ìƒíšŒí•˜ëŠ” ìˆ˜ì¤€ìœ¼ë¡œ, **í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±ì´ ë§¤ìš° íš¨ìœ¨ì **ì…ë‹ˆë‹¤.\n\n"
    elif sharpe_ratio > 1.0:
        reason += f"**âœ… ê· í˜• ì¡íŒ ë¦¬ìŠ¤í¬-ìˆ˜ìµ êµ¬ì¡°**\n\n"
        reason += f"ìƒ¤í”„ ì§€ìˆ˜ {sharpe_ratio:.3f}ëŠ” ì ì ˆí•œ ìœ„í—˜ ê´€ë¦¬ í•˜ì—ì„œ ì–‘í˜¸í•œ ìˆ˜ìµì„ ì¶”êµ¬í•˜ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ì…ë‹ˆë‹¤. "
        reason += f"ì‹œì¥ í‰ê·  ìˆ˜ì¤€ì˜ íš¨ìœ¨ì„±ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.\n\n"
    else:
        reason += f"**âš ï¸ ë³´ìˆ˜ì ì¸ í¬íŠ¸í´ë¦¬ì˜¤**\n\n"
        reason += f"ìƒ¤í”„ ì§€ìˆ˜ {sharpe_ratio:.3f}ëŠ” ì•ˆì •ì„±ì„ ì¤‘ì‹œí•˜ëŠ” êµ¬ì„±ì…ë‹ˆë‹¤. "
        reason += f"ë” ë†’ì€ ìˆ˜ìµì„ ì›í•˜ì‹ ë‹¤ë©´ ê³ ìˆ˜ìµ ì¢…ëª© ë¹„ì¤‘ì„ ëŠ˜ë ¤ë³´ì„¸ìš”.\n\n"
    
    # Risk level assessment
    if portfolio_risk < target_risk * 0.8:
        reason += f"**ğŸ“Œ ìœ„í—˜ ìˆ˜ì¤€ í‰ê°€:** ëª©í‘œ({target_risk})ë³´ë‹¤ ë‚®ì€ ë³€ë™ì„±({portfolio_risk:.1f}%)ìœ¼ë¡œ **ë§¤ìš° ì•ˆì •ì **ì´ì§€ë§Œ, "
        reason += f"ë” ê³µê²©ì ì¸ íˆ¬ìë¥¼ ì›í•˜ì‹ ë‹¤ë©´ ê³ ìˆ˜ìµ ì¢…ëª© ë¹„ì¤‘ì„ ëŠ˜ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
    elif portfolio_risk > target_risk * 1.3:
        reason += f"**âš ï¸ ìœ„í—˜ ìˆ˜ì¤€ í‰ê°€:** ëª©í‘œ({target_risk})ë³´ë‹¤ ë†’ì€ ë³€ë™ì„±({portfolio_risk:.1f}%)ìœ¼ë¡œ **ë³€ë™ì„± ì£¼ì˜**ê°€ í•„ìš”í•©ë‹ˆë‹¤. "
        reason += f"ë‹¨ê¸° ì†ì‹¤ ê°€ëŠ¥ì„±ì„ ì—¼ë‘ì— ë‘ì‹œê³ , í•„ìš”ì‹œ ì•ˆì •ì ì¸ ì¢…ëª© ë¹„ì¤‘ì„ ëŠ˜ë¦¬ì„¸ìš”.\n\n"
    else:
        reason += f"**âœ… ìœ„í—˜ ìˆ˜ì¤€ í‰ê°€:** ëª©í‘œ ìœ„í—˜ ìˆ˜ì¤€({target_risk})ì— ë¶€í•©í•˜ëŠ” ë³€ë™ì„±({portfolio_risk:.1f}%)ìœ¼ë¡œ **ì ì •í•œ í¬íŠ¸í´ë¦¬ì˜¤**ì…ë‹ˆë‹¤.\n\n"
    
    # Diversification effect
    if avg_correlation < 0.4:
        reason += f"**ğŸ¯ ë¶„ì‚°íˆ¬ì íš¨ê³¼:** ì¢…ëª© ê°„ ìƒê´€ê³„ìˆ˜ê°€ {avg_correlation:.3f}ë¡œ ë‚®ì•„ **íƒì›”í•œ ë¶„ì‚°íˆ¬ì íš¨ê³¼**ë¥¼ ë³´ì…ë‹ˆë‹¤. "
        reason += f"ê° ì¢…ëª©ì´ ì„œë¡œ ë‹¤ë¥¸ ì‹œì¥ ìƒí™©ì—ì„œ ë³´ì™„ì ìœ¼ë¡œ ì‘ë™í•˜ì—¬ ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ì˜ ì•ˆì •ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n\n"
    elif avg_correlation < 0.7:
        reason += f"**ğŸ¯ ë¶„ì‚°íˆ¬ì íš¨ê³¼:** ì¢…ëª© ê°„ ìƒê´€ê³„ìˆ˜ê°€ {avg_correlation:.3f}ë¡œ **ì ì ˆí•œ ë¶„ì‚°íš¨ê³¼**ë¥¼ ë³´ì…ë‹ˆë‹¤.\n\n"
    else:
        reason += f"**âš ï¸ ë¶„ì‚°íˆ¬ì íš¨ê³¼:** ì¢…ëª© ê°„ ìƒê´€ê³„ìˆ˜ê°€ {avg_correlation:.3f}ë¡œ ë†’ì•„ **ë¶„ì‚°íš¨ê³¼ê°€ ì œí•œì **ì…ë‹ˆë‹¤. "
        reason += f"ì„œë¡œ ë‹¤ë¥¸ ì‚°ì—…êµ°ì˜ ì¢…ëª©ì„ ì¶”ê°€í•˜ë©´ ë¦¬ìŠ¤í¬ë¥¼ ë” ë‚®ì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
    
    return reason


def generate_recommendation_reasons(stocks, weights, current_weights, returns):
    """Generate detailed reasons for each stock recommendation"""
    reasons = {}
    
    # Calculate average return for comparison
    avg_return = np.mean(returns) * 100
    
    for i, stock in enumerate(stocks):
        symbol = stock['symbol']
        name = stock['name']
        optimal_weight = weights[i] * 100
        current_weight = current_weights[i] * 100
        expected_return = returns[i] * 100
        risk_level = stock.get('riskLevel', 5.0)  # Default to 5.0 if None
        if risk_level is None:
            risk_level = 5.0
        
        diff = optimal_weight - current_weight
        
        if abs(diff) < 2:
            # ìœ ì§€ ì¶”ì²œ
            reason = f"**âœ… {name} ë³´ìœ  ë¹„ì¤‘ ìœ ì§€**\n\n"
            reason += f"í˜„ì¬ ë¹„ì¤‘ **{current_weight:.1f}%**ê°€ ìµœì  ìˆ˜ì¤€ì— ê·¼ì ‘í•©ë‹ˆë‹¤.\n\n"
            reason += f"**í˜„ì¬ ìƒíƒœ:**\n"
            reason += f"â€¢ ì˜ˆìƒ ì—°ê°„ ìˆ˜ìµë¥ : {expected_return:.1f}%\n"
            reason += f"â€¢ ìœ„í—˜ë„: {risk_level}/10\n"
            reason += f"â€¢ í¬íŠ¸í´ë¦¬ì˜¤ ê¸°ì—¬ë„: ì ì •\n\n"
            reason += f"**ìœ ì§€ ì´ìœ :**\n"
            reason += f"â€¢ í˜„ì¬ ë¹„ì¤‘ì´ ë¦¬ìŠ¤í¬-ìˆ˜ìµ ê· í˜•ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤\n"
            reason += f"â€¢ ì¶”ê°€ ì¡°ì • ì‹œ ê±°ë˜ë¹„ìš©ë§Œ ë°œìƒí•˜ê³  ê°œì„  íš¨ê³¼ê°€ ë¯¸ë¯¸í•©ë‹ˆë‹¤\n"
            reason += f"â€¢ í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ì•ˆì •ì„±ì— ì ì ˆíˆ ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤"
            reasons[symbol] = reason
            
        elif diff > 0:
            # ë§¤ìˆ˜ ì¶”ì²œ
            reason = f"**ğŸ“ˆ {name} ë¹„ì¤‘ ì¦ê°€ ({current_weight:.1f}% â†’ {optimal_weight:.1f}%)**\n\n"
            reason += f"**{abs(diff):.1f}%p ì¦ê°€**ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤ (ì•½ â‚©{abs(diff) * 100000:,.0f} ì¶”ê°€ íˆ¬ì)\n\n"
            
            reason += f"**ì¦ê°€ ì¶”ì²œ ì´ìœ :**\n\n"
            
            # Reason 1: Return analysis
            if expected_return > avg_return * 1.2:
                reason += f"1. **ë†’ì€ ìˆ˜ìµ ì ì¬ë ¥** ğŸ¯\n"
                reason += f"   - ì˜ˆìƒ ì—°ê°„ ìˆ˜ìµë¥ : **{expected_return:.1f}%**\n"
                reason += f"   - í¬íŠ¸í´ë¦¬ì˜¤ í‰ê· ({avg_return:.1f}%)ë³´ë‹¤ **{expected_return - avg_return:.1f}%p ë†’ìŒ**\n"
                reason += f"   - ê³ ìˆ˜ìµ ì¢…ëª©ìœ¼ë¡œ ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  í–¥ìƒì— ê¸°ì—¬\n\n"
            elif expected_return > avg_return:
                reason += f"1. **ì•ˆì •ì ì¸ ìˆ˜ìµ ê¸°ëŒ€** ğŸ“Š\n"
                reason += f"   - ì˜ˆìƒ ì—°ê°„ ìˆ˜ìµë¥ : **{expected_return:.1f}%**\n"
                reason += f"   - í¬íŠ¸í´ë¦¬ì˜¤ í‰ê·  ì´ìƒì˜ ì„±ê³¼ ê¸°ëŒ€\n\n"
            
            # Reason 2: Risk analysis
            if risk_level < 5:
                reason += f"2. **ë‚®ì€ ìœ„í—˜ë„ë¡œ ì•ˆì •ì ** ğŸ›¡ï¸\n"
                reason += f"   - ìœ„í—˜ë„: **{risk_level}/10** (ë‚®ìŒ)\n"
                reason += f"   - ë³€ë™ì„±ì´ ë‚®ì•„ í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ë¦¬ìŠ¤í¬ ê°ì†Œ\n"
                reason += f"   - ì‹œì¥ í•˜ë½ ì‹œì—ë„ ì†ì‹¤ ì œí•œ íš¨ê³¼\n\n"
            elif risk_level <= 7:
                reason += f"2. **ì ì •í•œ ìœ„í—˜ ìˆ˜ì¤€** âš–ï¸\n"
                reason += f"   - ìœ„í—˜ë„: **{risk_level}/10** (ì¤‘ê°„)\n"
                reason += f"   - ìˆ˜ìµ-ë¦¬ìŠ¤í¬ ê· í˜•ì´ ì¢‹ì€ ì¢…ëª©\n\n"
            else:
                reason += f"2. **ê³ ìœ„í—˜-ê³ ìˆ˜ìµ ì „ëµ** ğŸš€\n"
                reason += f"   - ìœ„í—˜ë„: **{risk_level}/10** (ë†’ìŒ)\n"
                reason += f"   - ë†’ì€ ë³€ë™ì„±ì´ì§€ë§Œ ëŒ€ê·œëª¨ ìˆ˜ìµ ê¸°íšŒ\n"
                reason += f"   - ë¶„ì‚°íˆ¬ìë¡œ ë¦¬ìŠ¤í¬ ê´€ë¦¬ í•„ìš”\n\n"
            
            # Reason 3: Portfolio optimization
            reason += f"3. **í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” íš¨ê³¼** ğŸ’¡\n"
            reason += f"   - ë‹¤ë¥¸ ì¢…ëª©ê³¼ì˜ **ë¶„ì‚° íš¨ê³¼**ë¡œ ì „ì²´ ë¦¬ìŠ¤í¬ ê°ì†Œ\n"
            reason += f"   - ìƒ¤í”„ ì§€ìˆ˜(ìœ„í—˜ ëŒ€ë¹„ ìˆ˜ìµ) ê°œì„ \n"
            reason += f"   - ëª©í‘œ ìœ„í—˜ ìˆ˜ì¤€ ë‚´ì—ì„œ ìˆ˜ìµ ê·¹ëŒ€í™”\n\n"
            
            reason += f"**íˆ¬ì ì „ëµ:** ë¹„ì¤‘ì„ ëŠ˜ë ¤ í¬íŠ¸í´ë¦¬ì˜¤ íš¨ìœ¨ì„±ì„ ë†’ì´ì„¸ìš”."
            reasons[symbol] = reason
            
        else:
            # ë§¤ë„ ì¶”ì²œ
            reason = f"**ğŸ“‰ {name} ë¹„ì¤‘ ê°ì†Œ ({current_weight:.1f}% â†’ {optimal_weight:.1f}%)**\n\n"
            reason += f"**{abs(diff):.1f}%p ê°ì†Œ**ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤ (ì•½ â‚©{abs(diff) * 100000:,.0f} ë§¤ë„)\n\n"
            
            reason += f"**ê°ì†Œ ì¶”ì²œ ì´ìœ :**\n\n"
            
            # Reason 1: Return analysis
            if expected_return < avg_return * 0.8:
                reason += f"1. **ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì€ ìˆ˜ìµë¥ ** ğŸ“Š\n"
                reason += f"   - ì˜ˆìƒ ì—°ê°„ ìˆ˜ìµë¥ : **{expected_return:.1f}%**\n"
                reason += f"   - í¬íŠ¸í´ë¦¬ì˜¤ í‰ê· ({avg_return:.1f}%)ë³´ë‹¤ **{abs(expected_return - avg_return):.1f}%p ë‚®ìŒ**\n"
                reason += f"   - ë” ë†’ì€ ìˆ˜ìµ ì¢…ëª©ìœ¼ë¡œ ìê¸ˆ ì¬ë°°ì¹˜ í•„ìš”\n\n"
            elif expected_return < avg_return:
                reason += f"1. **ìˆ˜ìµë¥  ê°œì„  ì—¬ì§€** ğŸ“ˆ\n"
                reason += f"   - ì˜ˆìƒ ìˆ˜ìµë¥ : **{expected_return:.1f}%**\n"
                reason += f"   - ë‹¤ë¥¸ ì¢…ëª© ëŒ€ë¹„ ì„±ê³¼ê°€ ë‚®ì€ í¸\n\n"
            
            # Reason 2: Risk analysis
            if risk_level > 7:
                reason += f"2. **ë†’ì€ ë³€ë™ì„± ë¦¬ìŠ¤í¬** âš ï¸\n"
                reason += f"   - ìœ„í—˜ë„: **{risk_level}/10** (ë†’ìŒ)\n"
                reason += f"   - ê³¼ë„í•œ ë¹„ì¤‘ì€ í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ë³€ë™ì„± ì¦ê°€\n"
                reason += f"   - ì‹œì¥ í•˜ë½ ì‹œ í° ì†ì‹¤ ê°€ëŠ¥ì„±\n\n"
            else:
                reason += f"2. **íš¨ìœ¨ì„± ê°œì„ ** ğŸ¯\n"
                reason += f"   - í˜„ì¬ ë¹„ì¤‘ì´ ìµœì  ìˆ˜ì¤€ë³´ë‹¤ ë†’ìŒ\n"
                reason += f"   - ë¹„ì¤‘ ì¡°ì •ìœ¼ë¡œ ë‹¤ë¥¸ ì¢…ëª© íˆ¬ì ê¸°íšŒ í™•ë³´\n\n"
            
            # Reason 3: Concentration risk
            if current_weight > 30:
                reason += f"3. **ì§‘ì¤‘ ë¦¬ìŠ¤í¬ ì™„í™”** ğŸ›¡ï¸\n"
                reason += f"   - í˜„ì¬ ë¹„ì¤‘({current_weight:.1f}%)ì´ ì§€ë‚˜ì¹˜ê²Œ ë†’ìŒ\n"
                reason += f"   - íŠ¹ì • ì¢…ëª© ì˜ì¡´ë„ê°€ ë†’ì•„ ìœ„í—˜\n"
                reason += f"   - ë¶„ì‚°íˆ¬ìë¡œ ì•ˆì •ì„± í™•ë³´ í•„ìš”\n\n"
            else:
                reason += f"3. **í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë°¸ëŸ°ì‹±** âš–ï¸\n"
                reason += f"   - ë‹¤ë¥¸ ê³ ìˆ˜ìµ ì¢…ëª©ìœ¼ë¡œ ìê¸ˆ ì¬ë°°ì¹˜\n"
                reason += f"   - ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ ìƒ¤í”„ ì§€ìˆ˜ ê°œì„ \n"
                reason += f"   - ë” íš¨ìœ¨ì ì¸ ë¦¬ìŠ¤í¬-ìˆ˜ìµ êµ¬ì¡° êµ¬ì¶•\n\n"
            
            reason += f"**íˆ¬ì ì „ëµ:** ë¹„ì¤‘ì„ ì¤„ì—¬ ìê¸ˆì„ ë” íš¨ìœ¨ì ìœ¼ë¡œ ë°°ë¶„í•˜ì„¸ìš”."
            reasons[symbol] = reason
    
    return reasons


def optimize_with_qaoa(n, returns, covariance_matrix, risk_factor):
    """
    Portfolio optimization using QAOA (Quantum Approximate Optimization Algorithm)
    Suitable for large portfolios (20+ stocks) with complex constraints
    """
    if not QUANTUM_AVAILABLE:
        print("QAOA not available, falling back to MPT", file=sys.stderr)
        return optimize_with_modern_portfolio_theory(n, returns, covariance_matrix, risk_factor)
    
    try:
        print("Running QAOA optimization...", file=sys.stderr)
        start_time = time.time()
        
        # Create quadratic program for portfolio optimization
        qp = QuadraticProgram('portfolio')
        
        # Add binary variables for each asset (discretized weights)
        # Using 4 bits per asset gives 16 possible weight levels (0-15)
        bits_per_asset = 4
        max_weight_value = 2**bits_per_asset - 1
        
        # Add variables
        for i in range(n):
            for bit in range(bits_per_asset):
                qp.binary_var(f'x_{i}_{bit}')
        
        # Objective: Maximize return - risk_factor * variance
        # Simplified objective for quantum optimization
        linear_coeffs = {}
        quadratic_coeffs = {}
        
        # Linear terms (returns)
        for i in range(n):
            for bit in range(bits_per_asset):
                bit_value = 2**bit / max_weight_value
                var_name = f'x_{i}_{bit}'
                linear_coeffs[var_name] = -returns[i] * bit_value  # Negative for minimization
        
        # Quadratic terms (risk penalty)
        risk_penalty = risk_factor * 2.0
        for i in range(n):
            for j in range(n):
                for bit_i in range(bits_per_asset):
                    for bit_j in range(bits_per_asset):
                        bit_value_i = 2**bit_i / max_weight_value
                        bit_value_j = 2**bit_j / max_weight_value
                        var_i = f'x_{i}_{bit_i}'
                        var_j = f'x_{j}_{bit_j}'
                        coeff = risk_penalty * covariance_matrix[i, j] * bit_value_i * bit_value_j
                        quadratic_coeffs[(var_i, var_j)] = coeff
        
        # Set objective
        qp.minimize(linear=linear_coeffs, quadratic=quadratic_coeffs)
        
        # Convert to QUBO
        converter = QuadraticProgramToQubo()
        qubo = converter.convert(qp)
        
        # Setup QAOA
        sampler = Sampler()
        qaoa = QAOA(sampler=sampler, optimizer=COBYLA(), reps=2)
        
        # Run optimization
        optimizer = MinimumEigenOptimizer(qaoa)
        result = optimizer.solve(qubo)
        
        # Extract weights from result
        weights = np.zeros(n)
        for i in range(n):
            for bit in range(bits_per_asset):
                var_name = f'x_{i}_{bit}'
                if var_name in result.variables_dict:
                    if result.variables_dict[var_name] > 0.5:
                        weights[i] += 2**bit / max_weight_value
        
        # Normalize weights
        if weights.sum() > 0:
            weights = weights / weights.sum()
        else:
            weights = np.ones(n) / n
        
        elapsed = time.time() - start_time
        print(f"QAOA completed in {elapsed:.2f} seconds", file=sys.stderr)
        
        return weights
        
    except Exception as e:
        print(f"QAOA optimization failed: {e}", file=sys.stderr)
        print("Falling back to MPT", file=sys.stderr)
        return optimize_with_modern_portfolio_theory(n, returns, covariance_matrix, risk_factor)


def optimize_with_vqe(n, returns, covariance_matrix, risk_factor):
    """
    Portfolio optimization using VQE (Variational Quantum Eigensolver)
    Advanced quantum algorithm for research purposes
    """
    if not QUANTUM_AVAILABLE:
        print("VQE not available, falling back to MPT", file=sys.stderr)
        return optimize_with_modern_portfolio_theory(n, returns, covariance_matrix, risk_factor)
    
    try:
        print("Running VQE optimization...", file=sys.stderr)
        start_time = time.time()
        
        # Create simplified problem for VQE (using fewer qubits)
        # Each qubit represents whether to include an asset
        qp = QuadraticProgram('portfolio_vqe')
        
        # Add binary variables
        for i in range(n):
            qp.binary_var(f'x_{i}')
        
        # Simplified objective
        linear_coeffs = {}
        quadratic_coeffs = {}
        
        # Returns (negative for minimization)
        for i in range(n):
            linear_coeffs[f'x_{i}'] = -returns[i]
        
        # Risk penalty
        risk_penalty = risk_factor * 2.0
        for i in range(n):
            for j in range(n):
                quadratic_coeffs[(f'x_{i}', f'x_{j}')] = risk_penalty * covariance_matrix[i, j]
        
        qp.minimize(linear=linear_coeffs, quadratic=quadratic_coeffs)
        
        # Convert to QUBO
        converter = QuadraticProgramToQubo()
        qubo = converter.convert(qp)
        
        # Setup VQE with TwoLocal ansatz
        ansatz = TwoLocal(n, 'ry', 'cz', reps=3, entanglement='linear')
        sampler = Sampler()
        vqe = VQE(sampler=sampler, ansatz=ansatz, optimizer=SLSQP())
        
        # Run optimization
        optimizer = MinimumEigenOptimizer(vqe)
        result = optimizer.solve(qubo)
        
        # Extract weights (binary decision + equal distribution)
        weights = np.zeros(n)
        selected = []
        for i in range(n):
            var_name = f'x_{i}'
            if var_name in result.variables_dict and result.variables_dict[var_name] > 0.5:
                selected.append(i)
        
        # Distribute equally among selected assets
        if selected:
            for i in selected:
                weights[i] = 1.0 / len(selected)
        else:
            weights = np.ones(n) / n
        
        elapsed = time.time() - start_time
        print(f"VQE completed in {elapsed:.2f} seconds", file=sys.stderr)
        
        return weights
        
    except Exception as e:
        print(f"VQE optimization failed: {e}", file=sys.stderr)
        print("Falling back to MPT", file=sys.stderr)
        return optimize_with_modern_portfolio_theory(n, returns, covariance_matrix, risk_factor)


def main():
    if len(sys.argv) < 3:
        print("Usage: optimize_portfolio.py <input_json_file> <session_id> [method] [use_real_data]", file=sys.stderr)
        sys.exit(1)
    
    input_file = sys.argv[1]
    session_id = sys.argv[2]
    method = sys.argv[3].upper() if len(sys.argv) > 3 else 'MPT'
    use_real_data = sys.argv[4].lower() == 'true' if len(sys.argv) > 4 else True
    
    try:
        # Load input data
        request_data = load_input_data(input_file)
        stocks = request_data['stocks']
        total_investment = request_data.get('totalInvestment', 10000)
        target_risk = request_data.get('targetRiskLevel', 5)
        use_real_data_from_request = request_data.get('useRealData', use_real_data)
        
        # Parse constraints if provided
        constraints = None
        if 'constraints' in request_data:
            constraints_data = request_data['constraints']
            min_weights = np.array([constraints_data.get(stock['symbol'], {}).get('min', 0.0) for stock in stocks])
            max_weights = np.array([constraints_data.get(stock['symbol'], {}).get('max', 1.0) for stock in stocks])
            constraints = {
                'min_weights': min_weights,
                'max_weights': max_weights
            }
            print(f"Using constraints: min={min_weights}, max={max_weights}", file=sys.stderr)
        
        # Fetch historical data and calculate statistics
        returns, covariance_matrix = fetch_historical_data(stocks, use_real_data=use_real_data_from_request)
        
        # Build optimization problem
        risk_factor = target_risk / 10.0  # Normalize to [0, 1]
        n, returns, covariance_matrix, risk_factor = build_portfolio_optimization_problem(
            returns, covariance_matrix, risk_factor
        )
        
        # Select optimization method
        if method == 'QAOA':
            weights = optimize_with_qaoa(n, returns, covariance_matrix, risk_factor)
            method_name = 'QAOA (Quantum Approximate Optimization Algorithm)'
        elif method == 'VQE':
            weights = optimize_with_vqe(n, returns, covariance_matrix, risk_factor)
            method_name = 'VQE (Variational Quantum Eigensolver)'
        else:
            weights = optimize_with_modern_portfolio_theory(n, returns, covariance_matrix, risk_factor, constraints)
            method_name = 'Modern Portfolio Theory (MPT)'
        
        # Calculate allocations
        allocations = calculate_allocations(stocks, weights)
        
        # Calculate portfolio metrics
        metrics = calculate_portfolio_metrics(returns, covariance_matrix, weights)
        
        # Calculate current portfolio weights
        # Support both quantity/currentPrice and investmentAmount formats
        if 'quantity' in stocks[0] and 'currentPrice' in stocks[0]:
            total_current_value = sum(stock['quantity'] * stock['currentPrice'] for stock in stocks)
            current_weights = np.array([
                (stock['quantity'] * stock['currentPrice']) / total_current_value 
                if total_current_value > 0 else 1.0 / len(stocks)
                for stock in stocks
            ])
        else:
            # Use investmentAmount
            total_investment_value = sum(stock.get('investmentAmount', 0) for stock in stocks)
            current_weights = np.array([
                stock.get('investmentAmount', 0) / total_investment_value
                if total_investment_value > 0 else 1.0 / len(stocks)
                for stock in stocks
            ])
        
        # Generate optimization reason
        optimization_reason = generate_optimization_reason(
            stocks, weights, returns, covariance_matrix, metrics, target_risk
        )
        
        # Generate recommendation reasons
        recommendation_reasons = generate_recommendation_reasons(
            stocks, weights, current_weights, returns
        )
        
        # Generate efficient frontier
        efficient_frontier = generate_efficient_frontier(returns, covariance_matrix, num_portfolios=100)
        
        # Calculate current portfolio metrics
        current_metrics = calculate_portfolio_metrics(returns, covariance_matrix, current_weights)
        
        # Run backtesting if using real data
        backtest_results = []
        if use_real_data:
            print("Running backtesting...", file=sys.stderr)
            backtest_results = backtest_optimization(stocks, periods=['3mo', '6mo', '1y'])
        
        # Prepare result
        result = {
            'allocation': allocations,
            'expectedReturn': metrics['expectedReturn'],
            'expectedRisk': metrics['expectedRisk'],
            'sharpeRatio': metrics['sharpeRatio'],
            'optimizationReason': optimization_reason,
            'recommendationReasons': recommendation_reasons,
            'visualizationPath': f'/api/visualization/{session_id}',
            'efficientFrontier': efficient_frontier,
            'currentPortfolio': {
                'risk': current_metrics['expectedRisk'],
                'return': current_metrics['expectedReturn'],
                'sharpe': current_metrics['sharpeRatio']
            },
            'optimizedPortfolio': {
                'risk': metrics['expectedRisk'],
                'return': metrics['expectedReturn'],
                'sharpe': metrics['sharpeRatio']
            },
            'backtestResults': backtest_results,
            'additionalMetrics': {
                'optimizationMethod': method_name,
                'numberOfStocks': len(stocks),
                'totalInvestment': total_investment,
                'timestamp': datetime.now().isoformat()
            }
        }
        
        # Output result as JSON
        print(json.dumps(result))
        
    except Exception as e:
        import traceback
        print(f"Error occurred: {str(e)}", file=sys.stderr)
        print(f"Traceback:", file=sys.stderr)
        traceback.print_exc(file=sys.stderr)
        error_result = {
            'error': str(e),
            'allocation': {},
            'expectedReturn': 0.0,
            'expectedRisk': 0.0,
            'sharpeRatio': 0.0,
            'visualizationPath': '',
            'additionalMetrics': {}
        }
        print(json.dumps(error_result))
        sys.exit(1)


if __name__ == '__main__':
    main()
